{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "(1459, 2)\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('./data/test.csv')\n",
    "train=pd.read_csv('./data/train.csv')\n",
    "sample=pd.read_csv('./data/sample_submission.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为: (2917, 79)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2917 entries, 0 to 2916\n",
      "Data columns (total 79 columns):\n",
      "MSSubClass       2917 non-null int64\n",
      "MSZoning         2913 non-null object\n",
      "LotFrontage      2431 non-null float64\n",
      "LotArea          2917 non-null int64\n",
      "Street           2917 non-null object\n",
      "Alley            198 non-null object\n",
      "LotShape         2917 non-null object\n",
      "LandContour      2917 non-null object\n",
      "Utilities        2915 non-null object\n",
      "LotConfig        2917 non-null object\n",
      "LandSlope        2917 non-null object\n",
      "Neighborhood     2917 non-null object\n",
      "Condition1       2917 non-null object\n",
      "Condition2       2917 non-null object\n",
      "BldgType         2917 non-null object\n",
      "HouseStyle       2917 non-null object\n",
      "OverallQual      2917 non-null int64\n",
      "OverallCond      2917 non-null int64\n",
      "YearBuilt        2917 non-null int64\n",
      "YearRemodAdd     2917 non-null int64\n",
      "RoofStyle        2917 non-null object\n",
      "RoofMatl         2917 non-null object\n",
      "Exterior1st      2916 non-null object\n",
      "Exterior2nd      2916 non-null object\n",
      "MasVnrType       2893 non-null object\n",
      "MasVnrArea       2894 non-null float64\n",
      "ExterQual        2917 non-null object\n",
      "ExterCond        2917 non-null object\n",
      "Foundation       2917 non-null object\n",
      "BsmtQual         2836 non-null object\n",
      "BsmtCond         2835 non-null object\n",
      "BsmtExposure     2835 non-null object\n",
      "BsmtFinType1     2838 non-null object\n",
      "BsmtFinSF1       2916 non-null float64\n",
      "BsmtFinType2     2837 non-null object\n",
      "BsmtFinSF2       2916 non-null float64\n",
      "BsmtUnfSF        2916 non-null float64\n",
      "TotalBsmtSF      2916 non-null float64\n",
      "Heating          2917 non-null object\n",
      "HeatingQC        2917 non-null object\n",
      "CentralAir       2917 non-null object\n",
      "Electrical       2916 non-null object\n",
      "1stFlrSF         2917 non-null int64\n",
      "2ndFlrSF         2917 non-null int64\n",
      "LowQualFinSF     2917 non-null int64\n",
      "GrLivArea        2917 non-null int64\n",
      "BsmtFullBath     2915 non-null float64\n",
      "BsmtHalfBath     2915 non-null float64\n",
      "FullBath         2917 non-null int64\n",
      "HalfBath         2917 non-null int64\n",
      "BedroomAbvGr     2917 non-null int64\n",
      "KitchenAbvGr     2917 non-null int64\n",
      "KitchenQual      2916 non-null object\n",
      "TotRmsAbvGrd     2917 non-null int64\n",
      "Functional       2915 non-null object\n",
      "Fireplaces       2917 non-null int64\n",
      "FireplaceQu      1497 non-null object\n",
      "GarageType       2760 non-null object\n",
      "GarageYrBlt      2758 non-null float64\n",
      "GarageFinish     2758 non-null object\n",
      "GarageCars       2916 non-null float64\n",
      "GarageArea       2916 non-null float64\n",
      "GarageQual       2758 non-null object\n",
      "GarageCond       2758 non-null object\n",
      "PavedDrive       2917 non-null object\n",
      "WoodDeckSF       2917 non-null int64\n",
      "OpenPorchSF      2917 non-null int64\n",
      "EnclosedPorch    2917 non-null int64\n",
      "3SsnPorch        2917 non-null int64\n",
      "ScreenPorch      2917 non-null int64\n",
      "PoolArea         2917 non-null int64\n",
      "PoolQC           9 non-null object\n",
      "Fence            571 non-null object\n",
      "MiscFeature      105 non-null object\n",
      "MiscVal          2917 non-null int64\n",
      "MoSold           2917 non-null int64\n",
      "YrSold           2917 non-null int64\n",
      "SaleType         2916 non-null object\n",
      "SaleCondition    2917 non-null object\n",
      "dtypes: float64(11), int64(25), object(43)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "##################删除训练集和测试集中的标签列-【开始】#################\n",
    "#将train矩阵中的'Id'列删除（原地删除，故将inplace设为true），因为原始数据中的数据索引和预测模型的构建没有关系。\n",
    "#test矩阵类似。\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "##################删除训练集和测试集中的标签列-【结束】#################\n",
    "\n",
    "###############删除训练集中的极端值和进行数据index更新-【开始】#########\n",
    "#使用条件筛选操作，通过覆值的方式剔除原始数据train矩阵中的极端值（极端值也被称为outliers），帮助预防房价预测模型出现过拟合。剔除操作也可以视为前剪枝。\n",
    "train = train[train.GrLivArea < 4500]\n",
    "#由于删去了部分行，故此时train矩阵中的index列并不连续。使用reset_index命令，在固定非index数据的顺序的前提下（inplace=True），重新对index编号（drop=True）。\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "###############删除训练集中的极端值和进行数据index更新-【结束】#########\n",
    "\n",
    "##########对预测目标数值进行对数变换和特征矩阵对象的创建-【开始】#######\n",
    "# log1p就是log(1+x)，用来对房价数据进行数据预处理，它的好处是转化后的数据更加服从高斯分布，有利于后续的分类结果。\n",
    "# 需要注意，最后需要将预测出的平滑数据还原，而还原过程就是log1p的逆运算expm1。\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "#单独取出训练数据中的房价列信息，存入y对象。\n",
    "#y = train.SalePrice.reset_index(drop=True) #.reset_index(drop=True)方法：在原有的索引列重置索引，不再另外添加新列。有必要使用reset_index吗？有必要的，不这样做y将有两套index，作为df的y将有两列。\n",
    "y = train['SalePrice'].reset_index(drop=True) #对上式的改写\n",
    "#沿着水平的方向寻找列名为'SalePrice'的列（们），把它们对应的列统统删掉。得到了单纯的特征矩阵，存入train_features对象中。\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "#test本来就没有房价列，所以它本来就是单纯的特征矩阵。\n",
    "test_features = test\n",
    "##########对预测目标数值进行对数变换和特征矩阵对象的创建-【结束】#######\n",
    "\n",
    "##合并训练数据特征矩阵与测试数据特征矩阵，以便统一进行特征处理-【开始】##\n",
    "#将训练数据中的特征矩阵和测试数据中的特征矩阵合并（.concat[矩阵1,矩阵2]），并对合并后的矩阵index重新编号（.reset_index(drop=True)）。\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "#检查合并后的矩阵的维数，核查合并结果。\n",
    "print(\"剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为:\",features.shape)\n",
    "features.info()\n",
    "##合并训练数据特征矩阵与测试数据特征矩阵，以便统一进行特征处理-【结束】##\n",
    "#######################################################数据导入和特征提取-【结束】################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########把特征打印到文件，方便查看################\n",
    "features.head()\n",
    "features.to_csv(\"features.csv\", index=False)\n",
    "###########把特征打印到文件，方便查看 结束################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/dash/lib/python3.7/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/Applications/anaconda3/envs/dash/lib/python3.7/site-packages/scipy/stats/stats.py:3429: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "#############开始特征工程################# \n",
    "####首先进行缺失值的处理########\n",
    "#\n",
    "features['Functional'] = features['Functional'].fillna('Typ') #空值填充为str型数据'Typ'\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\") #空值填充为str型数据\"SBrkr\"\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") #空值填充为str型数据\"TA\"\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\") #空值填充为str型数据\"None\"\n",
    "\n",
    "#对于列名为'Exterior1st'、'Exterior2nd'、'SaleType' \"MSZoning\"的特征列，使用列中的众数填充空值。\n",
    "#\t1.先查找数据列中的众数：使用df.mode()[]方法\n",
    "#\t  解释：df.mode(0或1,0表示对列查找，1表示对行查找)[需要查找众数的df列的index（就是df中的第几列）]，将返回数据列中的众数\n",
    "#\t2.使用.fillna()方法进行填充\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) \n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n",
    "features['MSZoning']=features['MSZoning'].fillna(features['MSZoning'].mode()[0])\n",
    "\n",
    "\n",
    "\n",
    "#对于列名为'GarageYrBlt', 'GarageArea', 'GarageCars'的特征列，使用0填充空值。表示没有GARAGE。\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "\n",
    "#对于列名为'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'的特征列，使用字符串'None'填充空值。表示没有GARAGE。\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "    \n",
    "#对于列名为'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'的特征列，使用字符串'None'填充空值。表示没有BASEMENT.\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')\n",
    "    \n",
    "#使用传入矩阵（'LotFrontage'列）的中位数对传入矩阵中的空值进行填充。\n",
    "#先以'Neighborhood'为标签，以'LotFrontage'为被汇总序列。然后使用被汇总序列中的中位数，对原始矩阵'LotFrontage'列中的空值进行填充。\n",
    "#transform的特性是同维操作，最后输出结果的顺序和原始数据在序号上完全匹配。\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#对于整型和浮点型数据列，使用0填充其中的空值。\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))\n",
    "\n",
    "######################数字型数据列偏度校正-【开始】#######################\n",
    "#使用skew()方法，计算所有整型和浮点型数据列中，数据分布的偏度（skewness）。\n",
    "#偏度是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。亦称偏态、偏态系数。 \n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "#以0.5作为基准，统计偏度超过此数值的高偏度分布数据列，获取这些数据列的index。\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "#对高偏度数据进行处理，将其转化为正态分布。\n",
    "#Box和Cox提出的变换可以使线性回归模型满足线性性、独立性、方差齐次以及正态性的同时，又不丢失信息。\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))#这是boxcox1p的使用方法，参数的具体意义暂时不解释\n",
    "######################数字型数据列偏度校正-【结束】#######################\n",
    "\n",
    "\n",
    "#判断出features矩阵中列为对象的列，将列名存入objects叔祖。对于features矩阵中的各个列对象，将其列中的空值填充为'None'\n",
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "features.update(features[objects].fillna('None')) \n",
    "\n",
    "#简化特征。对于某些分布单调（比如100个数据中有99个的数值是0.9，另1个是0.1）的数字型数据列，进行01取值处理。\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2917 entries, 0 to 2916\n",
      "Data columns (total 84 columns):\n",
      "MSSubClass       2917 non-null float64\n",
      "MSZoning         2917 non-null object\n",
      "LotFrontage      2917 non-null float64\n",
      "LotArea          2917 non-null float64\n",
      "Street           2917 non-null object\n",
      "Alley            2917 non-null object\n",
      "LotShape         2917 non-null object\n",
      "LandContour      2917 non-null object\n",
      "Utilities        2917 non-null object\n",
      "LotConfig        2917 non-null object\n",
      "LandSlope        2917 non-null object\n",
      "Neighborhood     2917 non-null object\n",
      "Condition1       2917 non-null object\n",
      "Condition2       2917 non-null object\n",
      "BldgType         2917 non-null object\n",
      "HouseStyle       2917 non-null object\n",
      "OverallQual      2917 non-null int64\n",
      "OverallCond      2917 non-null float64\n",
      "YearBuilt        2917 non-null int64\n",
      "YearRemodAdd     2917 non-null int64\n",
      "RoofStyle        2917 non-null object\n",
      "RoofMatl         2917 non-null object\n",
      "Exterior1st      2917 non-null object\n",
      "Exterior2nd      2917 non-null object\n",
      "MasVnrType       2917 non-null object\n",
      "MasVnrArea       2917 non-null float64\n",
      "ExterQual        2917 non-null object\n",
      "ExterCond        2917 non-null object\n",
      "Foundation       2917 non-null object\n",
      "BsmtQual         2917 non-null object\n",
      "BsmtCond         2917 non-null object\n",
      "BsmtExposure     2917 non-null object\n",
      "BsmtFinType1     2917 non-null object\n",
      "BsmtFinSF1       2917 non-null float64\n",
      "BsmtFinType2     2917 non-null object\n",
      "BsmtFinSF2       2917 non-null float64\n",
      "BsmtUnfSF        2917 non-null float64\n",
      "TotalBsmtSF      2917 non-null float64\n",
      "Heating          2917 non-null object\n",
      "HeatingQC        2917 non-null object\n",
      "CentralAir       2917 non-null object\n",
      "Electrical       2917 non-null object\n",
      "1stFlrSF         2917 non-null float64\n",
      "2ndFlrSF         2917 non-null float64\n",
      "LowQualFinSF     2917 non-null float64\n",
      "GrLivArea        2917 non-null float64\n",
      "BsmtFullBath     2917 non-null float64\n",
      "BsmtHalfBath     2917 non-null float64\n",
      "FullBath         2917 non-null int64\n",
      "HalfBath         2917 non-null float64\n",
      "BedroomAbvGr     2917 non-null int64\n",
      "KitchenAbvGr     2917 non-null float64\n",
      "KitchenQual      2917 non-null object\n",
      "TotRmsAbvGrd     2917 non-null float64\n",
      "Functional       2917 non-null object\n",
      "Fireplaces       2917 non-null float64\n",
      "FireplaceQu      2917 non-null object\n",
      "GarageType       2917 non-null object\n",
      "GarageYrBlt      2917 non-null float64\n",
      "GarageFinish     2917 non-null object\n",
      "GarageCars       2917 non-null float64\n",
      "GarageArea       2917 non-null float64\n",
      "GarageQual       2917 non-null object\n",
      "GarageCond       2917 non-null object\n",
      "PavedDrive       2917 non-null object\n",
      "WoodDeckSF       2917 non-null float64\n",
      "OpenPorchSF      2917 non-null float64\n",
      "EnclosedPorch    2917 non-null float64\n",
      "3SsnPorch        2917 non-null float64\n",
      "ScreenPorch      2917 non-null float64\n",
      "PoolArea         2917 non-null float64\n",
      "PoolQC           2917 non-null object\n",
      "Fence            2917 non-null object\n",
      "MiscFeature      2917 non-null object\n",
      "MiscVal          2917 non-null float64\n",
      "MoSold           2917 non-null int64\n",
      "YrSold           2917 non-null int64\n",
      "SaleType         2917 non-null object\n",
      "SaleCondition    2917 non-null object\n",
      "haspool          2917 non-null int64\n",
      "has2ndfloor      2917 non-null int64\n",
      "hasgarage        2917 non-null int64\n",
      "hasbsmt          2917 non-null int64\n",
      "hasfireplace     2917 non-null int64\n",
      "dtypes: float64(29), int64(12), object(43)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "features.info()\n",
    "#features.to_csv(\"features3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################特征删除和融合创建新特征-【开始】###################\n",
    "#删除一些特征。df.drop（‘列名’, axis=1）代表将‘列名’对应的列标签（们）沿着水平的方向依次删掉。\n",
    "#features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>MoSold_3</th>\n",
       "      <th>MoSold_4</th>\n",
       "      <th>MoSold_5</th>\n",
       "      <th>MoSold_6</th>\n",
       "      <th>MoSold_7</th>\n",
       "      <th>MoSold_8</th>\n",
       "      <th>MoSold_9</th>\n",
       "      <th>MoSold_10</th>\n",
       "      <th>MoSold_11</th>\n",
       "      <th>MoSold_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.499671</td>\n",
       "      <td>18.144572</td>\n",
       "      <td>13.833054</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>19.433172</td>\n",
       "      <td>144.117870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.249693</td>\n",
       "      <td>20.673624</td>\n",
       "      <td>14.117918</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000033</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.719196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.499671</td>\n",
       "      <td>18.668046</td>\n",
       "      <td>14.476513</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>17.768838</td>\n",
       "      <td>110.441039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.862539</td>\n",
       "      <td>17.249650</td>\n",
       "      <td>14.106197</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.795317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.499671</td>\n",
       "      <td>21.314282</td>\n",
       "      <td>15.022008</td>\n",
       "      <td>8</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>25.404161</td>\n",
       "      <td>136.624608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage    LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    6.499671    18.144572  13.833054            7     3.991517       2003   \n",
       "1    4.249693    20.673624  14.117918            6     6.000033       1976   \n",
       "2    6.499671    18.668046  14.476513            7     3.991517       2001   \n",
       "3    6.862539    17.249650  14.106197            7     3.991517       1915   \n",
       "4    6.499671    21.314282  15.022008            8     3.991517       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  MoSold_3  MoSold_4  \\\n",
       "0          2003   19.433172  144.117870         0.0  ...         0         0   \n",
       "1          1976    0.000000  181.719196         0.0  ...         0         0   \n",
       "2          2002   17.768838  110.441039         0.0  ...         0         0   \n",
       "3          1970    0.000000   61.795317         0.0  ...         0         0   \n",
       "4          2000   25.404161  136.624608         0.0  ...         0         0   \n",
       "\n",
       "   MoSold_5  MoSold_6  MoSold_7  MoSold_8  MoSold_9  MoSold_10  MoSold_11  \\\n",
       "0         0         0         0         0         0          0          0   \n",
       "1         1         0         0         0         0          0          0   \n",
       "2         0         0         0         0         1          0          0   \n",
       "3         0         0         0         0         0          0          0   \n",
       "4         0         0         0         0         0          0          0   \n",
       "\n",
       "   MoSold_12  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########对下面几个特征进行分列#######\n",
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        temp = pd.get_dummies(features[i], prefix=features[[i]].columns[0])\n",
    "        features = pd.concat([features, temp], axis=1)\n",
    "\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        features = features.drop([i], axis=1)\n",
    "MSSubClass = pd.get_dummies(features['MSSubClass'], prefix=features[['MSSubClass']].columns[0])\n",
    "features = pd.concat([features, MSSubClass], axis=1)\n",
    "\n",
    "YrSold = pd.get_dummies(features['YrSold'], prefix=features[['YrSold']].columns[0])\n",
    "features = pd.concat([features, YrSold], axis=1)\n",
    "\n",
    "MoSold = pd.get_dummies(features['MoSold'], prefix=features[['MoSold']].columns[0])\n",
    "features = pd.concat([features, MoSold], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#融合多个特征，生成新特征。\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])\n",
    "\n",
    "features['yearslived'] = features['YrSold'] - features['YearBuilt']\n",
    "features['yearsremod'] = features['YrSold'] - features['YearRemodAdd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#还原到测试集和训练集\n",
    "train_data_X = features.iloc[:len(y), :]\t#y是列向量，存储了训练数据中的房价列信息。截取后得到的X阵的维度是len(y)*(final_features的列数)。\n",
    "test_data_X = features.iloc[len(y):, :]#使用len命令，求矩阵X的长度，得到的是矩阵对象的长度，即有矩阵中有多少列，而不是每列上有多少行。\n",
    "\n",
    "\n",
    "#在新生特征空间中，剔除X阵和y阵中有着极端值的各行数据（因为X和y阵在水平方向上是一致的，所以要一起删除同样的行）。outliers数值中给出了极端值的列序号。\n",
    "#df.drop(df.index[序号])将删除指定序号的各行。再使用=对df覆值。\n",
    "outliers = [30, 88, 462, 631, 1322]\n",
    "train_data_X = train_data_X.drop(train_data_X.index[outliers])#因为X阵是经过对特征矩阵进行类似“坐标投影”操作后得到的，列向量y中的行号对应着X阵中的列号。\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "train_data_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2917 entries, 0 to 2916\n",
      "Columns: 347 entries, MSSubClass to yearsremod\n",
      "dtypes: float64(33), int64(15), uint8(299)\n",
      "memory usage: 1.9 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1453 entries, 0 to 1457\n",
      "Columns: 347 entries, MSSubClass to yearsremod\n",
      "dtypes: float64(33), int64(15), uint8(299)\n",
      "memory usage: 980.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 1458 to 2916\n",
      "Columns: 347 entries, MSSubClass to yearsremod\n",
      "dtypes: float64(33), int64(15), uint8(299)\n",
      "memory usage: 973.3 KB\n"
     ]
    }
   ],
   "source": [
    "features.info()\n",
    "train_data_X.info()\n",
    "test_data_X.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面用几个模型来筛选比较重要的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【开始】############\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "#定义ridge岭回归模型（使用二范数作为正则化项。不论是使用一范数还是二范数，正则化项的引入均是为了降低过拟合风险。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\n",
    "# ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "#定义LASSO收缩模型（使用L1范数作为正则化项）（由于对目标函数的求解结果中将得到很多的零分量，它也被称为收缩模型。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\t\t\t\t\t\t\t\t\t\t\n",
    "# lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "\n",
    "#定义elastic net弹性网络模型（弹性网络实际上是结合了岭回归和lasso的特点，同时使用了L1和L2作为正则化项。）\t\t\t\t\t\t\t\t\t\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=5, l1_ratio=e_l1ratio))\n",
    "\n",
    "#定义random forest model\t\t\t\t\t\t\t\t\t\n",
    "rf = RandomForestRegressor(n_estimators=3000, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, criterion='mse', random_state =42)                             \n",
    "\n",
    "#定义GB梯度提升模型（展开到一阶导数）\t\t\t\t\t\t\t\t\t\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             \n",
    "\n",
    "#定义lightgbm模型\t\t\t\t\t\t\t\t\t\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       #min_data_in_leaf=2,\n",
    "                                       #min_sum_hessian_in_leaf=11\n",
    "                                       )\n",
    "\n",
    "#定义xgboost模型（展开到二阶导数）                                      \n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:squarederror', nthread=4,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【结束】############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_features(train_data_X, train_data_y, top_n_features,models = []):\n",
    "        # 随机森林\n",
    "    #定义xgboost模型（展开到二阶导数）  \n",
    "    features_top_n = []\n",
    "    for model in models:\n",
    "        \n",
    "#        scorings = -cross_val_score(model, train_data_X, train_data_y, cv=5, \n",
    "#                    scoring='neg_mean_squared_error',n_jobs=4)\n",
    "#        rmse = np.sqrt(scorings).mean()\n",
    "#        print(rmse)\n",
    "        model.fit(train_data_X, train_data_y)\n",
    "        #将feature按Importance排序\n",
    "        feature_imp_sorted_each = pd.DataFrame({'feature': list(train_data_X), 'importance': model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "        features_top_n_each = feature_imp_sorted_each.head(top_n_features)['feature']\n",
    "        print('Sample 25 Features from Classifier')\n",
    "        print(str(features_top_n_each[:25]))\n",
    "        if(len(features_top_n) == 0):\n",
    "            features_top_n = features_top_n_each\n",
    "        features_top_n = pd.concat([features_top_n,features_top_n_each], ignore_index=True).drop_duplicates()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return features_top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 25 Features from Classifier\n",
      "3           OverallQual\n",
      "15            GrLivArea\n",
      "345          yearslived\n",
      "5             YearBuilt\n",
      "343     Total_Bathrooms\n",
      "340       YrBltAndRemod\n",
      "25           GarageCars\n",
      "176        ExterQual_TA\n",
      "11          TotalBsmtSF\n",
      "26           GarageArea\n",
      "12             1stFlrSF\n",
      "24          GarageYrBlt\n",
      "18             FullBath\n",
      "341             TotalSF\n",
      "40         hasfireplace\n",
      "346          yearsremod\n",
      "249    FireplaceQu_None\n",
      "238      KitchenQual_TA\n",
      "23           Fireplaces\n",
      "184    Foundation_PConc\n",
      "6          YearRemodAdd\n",
      "175        ExterQual_Gd\n",
      "188         BsmtQual_Ex\n",
      "22         TotRmsAbvGrd\n",
      "2               LotArea\n",
      "Name: feature, dtype: object\n",
      "Sample 25 Features from Classifier\n",
      "343      Total_Bathrooms\n",
      "15             GrLivArea\n",
      "340        YrBltAndRemod\n",
      "3            OverallQual\n",
      "11           TotalBsmtSF\n",
      "238       KitchenQual_TA\n",
      "176         ExterQual_TA\n",
      "26            GarageArea\n",
      "18              FullBath\n",
      "25            GarageCars\n",
      "6           YearRemodAdd\n",
      "12              1stFlrSF\n",
      "23            Fireplaces\n",
      "2                LotArea\n",
      "249     FireplaceQu_None\n",
      "188          BsmtQual_Ex\n",
      "13              2ndFlrSF\n",
      "8             BsmtFinSF1\n",
      "22          TotRmsAbvGrd\n",
      "341              TotalSF\n",
      "344       Total_porch_sf\n",
      "342    Total_sqr_footage\n",
      "345           yearslived\n",
      "175         ExterQual_Gd\n",
      "5              YearBuilt\n",
      "Name: feature, dtype: object\n",
      "Sample 25 Features from Classifier\n",
      "2                    LotArea\n",
      "15                 GrLivArea\n",
      "12                  1stFlrSF\n",
      "11               TotalBsmtSF\n",
      "4                OverallCond\n",
      "26                GarageArea\n",
      "3                OverallQual\n",
      "10                 BsmtUnfSF\n",
      "8                 BsmtFinSF1\n",
      "340            YrBltAndRemod\n",
      "341                  TotalSF\n",
      "345               yearslived\n",
      "24               GarageYrBlt\n",
      "5                  YearBuilt\n",
      "344           Total_porch_sf\n",
      "342        Total_sqr_footage\n",
      "343          Total_Bathrooms\n",
      "346               yearsremod\n",
      "1                LotFrontage\n",
      "28               OpenPorchSF\n",
      "6               YearRemodAdd\n",
      "27                WoodDeckSF\n",
      "34                    MoSold\n",
      "301    SaleCondition_Abnorml\n",
      "245           Functional_Typ\n",
      "Name: feature, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/dash/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 25 Features from Classifier\n",
      "25                       GarageCars\n",
      "23                       Fireplaces\n",
      "40                     hasfireplace\n",
      "188                     BsmtQual_Ex\n",
      "249                FireplaceQu_None\n",
      "3                       OverallQual\n",
      "268                   GarageQual_TA\n",
      "343                 Total_Bathrooms\n",
      "15                        GrLivArea\n",
      "340                   YrBltAndRemod\n",
      "11                      TotalBsmtSF\n",
      "253               GarageType_Attchd\n",
      "173                    ExterQual_Ex\n",
      "174                    ExterQual_Fa\n",
      "228                    CentralAir_N\n",
      "45                      MSZoning_RM\n",
      "238                  KitchenQual_TA\n",
      "229                    CentralAir_Y\n",
      "308    MSSubClass_5.014201084298206\n",
      "140             Exterior1st_BrkComm\n",
      "235                  KitchenQual_Ex\n",
      "76             Neighborhood_Crawfor\n",
      "283                      Fence_GdWo\n",
      "244                  Functional_Sev\n",
      "220                    Heating_Grav\n",
      "Name: feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "feature_to_pick = 250\n",
    "models = [rf,gbr,lightgbm,xgboost]\n",
    "feature_top_n = get_top_n_features(train_data_X,train_data_y,feature_to_pick,models = models)\n",
    "picked_train_data_X = train_data_X[feature_top_n]\n",
    "picked_test_data_X = test_data_X[feature_top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面是STACKING 学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行交叉验证，计算不同模型的得分TEST score on CV\n",
      "elastic net弹性网络模型的得分: 0.1011 (0.0058)\n",
      " 2019-12-29 17:17:26.411762\n",
      "lightgbm轻梯度提升模型的得分: 0.1085 (0.0048)\n",
      " 2019-12-29 17:17:31.193905\n",
      "gbr梯度提升回归模型的得分: 0.1103 (0.0088)\n",
      " 2019-12-29 17:17:57.174081\n",
      "rf随机森林模型的得分: 0.1841 (0.0119)\n",
      " 2019-12-29 17:18:14.616052\n",
      "xgboost模型的得分: 0.1060 (0.0043)\n",
      " 2019-12-29 17:19:07.467209\n",
      "进行模型参数训练 START Fit\n",
      "2019-12-29 17:19:07.467487 对stack_gen集成器模型进行参数训练\n",
      "2019-12-29 17:22:06.804010 对elasticnet弹性网络模型进行参数训练\n",
      "2019-12-29 17:22:09.012141 对GradientBoosting梯度提升模型进行参数训练\n",
      "2019-12-29 17:22:21.039077 对xgboost二阶梯度提升模型进行参数训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/dash/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-29 17:22:38.963047 对lightgbm轻梯度提升模型进行参数训练\n",
      "2019-12-29 17:22:40.348754 对rf轻梯度提升模型进行参数训练\n"
     ]
    }
   ],
   "source": [
    "#定义均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "#创建模型评分函数，根据不同模型的表现打分\n",
    "#cv表示Cross-validation,交叉验证的意思。\n",
    "def cv_rmse(model, X=picked_train_data_X,y = train_data_y ):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\",cv = 5,n_jobs=4))\n",
    "    return (rmse)\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "#################投票集成 ##################\n",
    "#ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "###########################集成多个个体学习器-【开始】##########################\n",
    "stack_gen = StackingCVRegressor(regressors=(elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)#regressors=(...)中并没有纳入前面的svr模型\n",
    "###########################集成多个个体学习器-【结束】##########################                             \n",
    "\n",
    "############################进行交叉验证打分-【开始】###########################\n",
    "#进行交叉验证，并对不同模型的表现打分\n",
    "#（由于是交叉验证，将使用不同的数据集对同一模型进行评分，故每个模型对应一个得分序列。展示模型得分序列的平均分、标准差）\n",
    "print('进行交叉验证，计算不同模型的得分TEST score on CV')\n",
    "\n",
    "#打印elastic net弹性网络模型的得分\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net弹性网络模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印lightgbm轻梯度提升模型的得分\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm轻梯度提升模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印gbr梯度提升回归模型的得分\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr梯度提升回归模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印随机森林模型的得分\n",
    "score = cv_rmse(rf)\n",
    "print(\"rf随机森林模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印xgboost模型的得分\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "############################进行交叉验证打分-【结束】###########################\n",
    "\n",
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【开始】#########\n",
    "#开始集合所有模型，使用stacking方法\n",
    "print('进行模型参数训练 START Fit')\n",
    "\n",
    "print(datetime.now(), '对stack_gen集成器模型进行参数训练')\n",
    "stack_gen_model = stack_gen.fit(np.array(picked_train_data_X), np.array(train_data_y))\n",
    "\n",
    "print(datetime.now(), '对elasticnet弹性网络模型进行参数训练')\n",
    "elastic_model_full_data = elasticnet.fit(picked_train_data_X, train_data_y)\n",
    "\n",
    "print(datetime.now(), '对GradientBoosting梯度提升模型进行参数训练')\n",
    "gbr_model_full_data = gbr.fit(picked_train_data_X, train_data_y)\n",
    "\n",
    "print(datetime.now(), '对xgboost二阶梯度提升模型进行参数训练')\n",
    "xgb_model_full_data = xgboost.fit(picked_train_data_X, train_data_y)\n",
    "\n",
    "print(datetime.now(), '对lightgbm轻梯度提升模型进行参数训练')\n",
    "lgb_model_full_data = lightgbm.fit(picked_train_data_X, train_data_y)\n",
    "\n",
    "print(datetime.now(), '对rf轻梯度提升模型进行参数训练')\n",
    "rf_model_full_data = rf.fit(picked_train_data_X, train_data_y)\n",
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【结束】#########\n",
    "\n",
    "############################进行交叉验证打分-【结束】###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融合后的训练模型对原数据重构时的均方根对数误差RMSLE score on train data:\n",
      "0.04121973119132323\n",
      "使用测试集特征进行房价预测 Predict submission 2019-12-29 17:28:03.417952\n",
      "融合结果.csv文件输出成功 Save submission 2019-12-29 17:28:04.456863\n"
     ]
    }
   ],
   "source": [
    "#### 这 blend的 参数值是咋决定的？\n",
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【开始】#######\n",
    "#综合多个模型产生的预测值，作为多模型组合学习器的预测值\n",
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "#             (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "#             (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "#             (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.55 * stack_gen_model.predict(np.array(X))))\n",
    "\n",
    "#打印在上述模型配比下，多模型组合学习器的均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "#使用训练数据对创造的模型进行k折交叉验证，以训练创造出的模型的参数配置。交叉验证训练过程结束后，将得到模型的参数配置。使用得出的参数配置下，在全体训练数据上进行验证，验证模型对全体训练数据重构的误差。\n",
    "print('融合后的训练模型对原数据重构时的均方根对数误差RMSLE score on train data:')\n",
    "print(rmsle(train_data_y, blend_models_predict(picked_train_data_X)))\n",
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【结束】#######\n",
    "\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【开始】########\n",
    "print('使用测试集特征进行房价预测 Predict submission', datetime.now(),)\n",
    "submission = pd.read_csv(\"./submission/submission3_baseline.csv\")\n",
    "#函数注释：.iloc[:,1]是基于索引位来选取数据集，[索引1:索引2]，左闭右开。\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(picked_test_data_X)))\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【结束】########\n",
    "#以csv文件的形式输出预测值\n",
    "submission.to_csv(\"./submission/House_price_submission_ML1.csv\", index=False)\n",
    "print('融合结果.csv文件输出成功 Save submission', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dash)",
   "language": "python",
   "name": "dash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
